{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import img_pross_help as imgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Image Encoding\n",
    "key_dict = {\n",
    "    'laptop':[0,0,1],\n",
    "    'cup':[0,1,0],\n",
    "    'chair':[0,1,1],\n",
    "    'car':[1,0,0]\n",
    "}\n",
    "# Data Pre-process\n",
    "\n",
    "img_wh = 28 # Image Width and Height\n",
    "img_flat = img_wh**2 # The size of the image flattened\n",
    "img_shape = (img_wh,img_wh) # Holds the dimension of the image\n",
    "color_channels = 3 # RGB is a 3 color channel\n",
    "num_classes = 4 # 4 Total number of classification possibilities\n",
    "\n",
    "#imgh.PrepImages(\"images/all_source_images\",\"images/train_imgs\", \"images/test_imgs\",28,28,0.6) #Only needs to be ran initially\n",
    "train_Images,train_Labels = imgh.ImportImages(\"images/train_imgs\",key_dict) # Extract Training Images and Labels\n",
    "test_Images,test_Labels = imgh.ImportImages(\"images/test_imgs\",key_dict)# Extract Testing Images and Labels\n",
    "\n",
    "train_Images = imgh.shape_up_X(train_Images,img_wh,color_channels)\n",
    "test_Images = imgh.shape_up_X(test_Images,img_wh,color_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Shape:  (194, 3)\n",
      "Training Images Shape: (194, 28, 28, 3)\n",
      "Testing Label Shape:  (129, 3)\n",
      "Testing Images Shape: (129, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Label Shape: \",train_Labels.shape)\n",
    "print(\"Training Images Shape:\",train_Images.shape)\n",
    "print(\" \")\n",
    "print(\"Testing Label Shape: \",test_Labels.shape)\n",
    "print(\"Testing Images Shape:\",test_Images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Overview:\n",
    "An input layer of size 28x28x3 which will then go through a convolutional layer of size 5x5x10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_layer = tf,placeholder(tf.float32, shape=[None,])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
