{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import img_pross_help as imgh\n",
    "import tf_helper_funcs as tf_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Image Encoding\n",
    "key_dict = {\n",
    "    'laptop':[0,0,1],\n",
    "    'cup':[0,1,0],\n",
    "    'chair':[0,1,1],\n",
    "    'car':[1,0,0]\n",
    "}\n",
    "# Data Pre-process\n",
    "img_wh = 256 # Image Width and Height\n",
    "img_flat = img_wh**2 # The size of the image flattened\n",
    "img_shape = (img_wh,img_wh) # Holds the dimension of the image\n",
    "color_channels = 3 # RGB is a 3 color channel\n",
    "num_classes = 3 # 4 Total number of classification possibilities\n",
    "imgh.PrepImages(\"images/all_source_images\",\"images/train_imgs\", \"images/test_imgs\",img_wh,img_wh,0.6) #Only needs to be ran initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Shape:  (323, 3)\n",
      "Training Images Shape: (323, 256, 256, 3)\n",
      " \n",
      "Testing Label Shape:  (312, 3)\n",
      "Testing Images Shape: (312, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "train_Images,train_Labels = imgh.ImportImages(\"images/train_imgs\",key_dict) # Extract Training Images and Labels\n",
    "test_Images,test_Labels = imgh.ImportImages(\"images/test_imgs\",key_dict)# Extract Testing Images and Labels\n",
    "\n",
    "#train_Images = imgh.shape_up_X(train_Images,img_wh,color_channels,train_Labels.shape[0])\n",
    "#test_Images = imgh.shape_up_X(test_Images,img_wh,color_channels,test_Labels.shape[0])\n",
    "\n",
    "print(\"Training Label Shape: \",train_Labels.shape)\n",
    "print(\"Training Images Shape:\",train_Images.shape)\n",
    "print(\" \")\n",
    "print(\"Testing Label Shape: \",test_Labels.shape)\n",
    "print(\"Testing Images Shape:\",test_Images.shape)\n",
    "# Randomize Data\n",
    "for i in range(10):\n",
    "    r = np.random.permutation(range(len(train_Labels)))\n",
    "    train_Labels = train_Labels[r,:]\n",
    "    train_Images = train_Images[r,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Example: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Label Example: \")\n",
    "train_Labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Overview:\n",
    "An initial convolutional layer of size 28x28x10 and a filter size of 5x5 which will then go through a convolutional layer of size 14x14x15 with a filter size of 3 and using max pooling.\n",
    "\n",
    "A fully connected layer will then flatten out the resulting convlutional outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,img_wh, img_wh, color_channels]) # X Input Site\n",
    "x_image = tf.reshape(X, [-1, img_wh, img_wh, color_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_classes]) # Class Output Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  81920\n"
     ]
    }
   ],
   "source": [
    "# Create First Convolutional Layer\n",
    "CONV_L1, W_L1 = tf_help.new_conv_layer(x_image, color_channels, 16, 60,False)\n",
    "\n",
    "# Create Second Convolutional Layer\n",
    "CONV_L2, W_L2 = tf_help.new_conv_layer(CONV_L1, 60, 8, 30)\n",
    "\n",
    "# Create Third Convolutional Layer with Pooling\n",
    "CONV_L3, W_L3 = tf_help.new_conv_layer(CONV_L2, 30, 5, 20)\n",
    "# Flatten Second Convolutional Layer and Create Fully Connected Layer\n",
    "\n",
    "flt_layer, features = tf_help.flatten_layer(CONV_L3)\n",
    "print(\"Features: \", features)\n",
    "FC_L1 = tf_help.fc_layer(flt_layer,features,512)\n",
    "\n",
    "# Create Another Fully Connected Layer\n",
    "\n",
    "FC_L2 = tf_help.fc_layer(FC_L1,512,num_classes,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 256, 256, 60) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONV_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 128, 128, 30) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONV_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 64, 64, 20) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONV_L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 512) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4:0' shape=(?, 3) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                # Build and Connect Model\n",
    "# Y\n",
    "y_out = tf.nn.softmax(FC_L2) # Prototype Y output vector\n",
    "#y_class = tf.argmax(y_out,axis=1) # Keep Largest Element of Vector\n",
    "y_class = y_out\n",
    "# Cost Function\n",
    "cost_fun = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = FC_L2, labels = Y))\n",
    "\n",
    "# Cost Optimization\n",
    "optimize_fun = tf.train.GradientDescentOptimizer(0.02).minimize(cost_fun)\n",
    "#optimize_fun = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost_fun)\n",
    "\n",
    "# Accuracy Measurements\n",
    "correct_ =  tf.equal(tf.cast(y_out, tf.float32), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Session\n",
    "session = tf.InteractiveSession()\n",
    "session.run(tf.global_variables_initializer())\n",
    "# Define Batch Size for Train Step\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                # Training Step\n",
    "for i in range(100):\n",
    "    r = np.random.permutation(range(len(train_Labels)))\n",
    "    train_Labels = train_Labels[r,:]\n",
    "    train_Images = train_Images[r,:]\n",
    "    for j in range(len(train_Images),batch_size):\n",
    "        img_set = train_Images[j,:]\n",
    "        print(len(img_set))\n",
    "        lab_set = train_Labels[j,:]\n",
    "        opt_res = session.run(optimize_fun,feed_dict = {X:img_set, Y:lab_set})\n",
    "        print(opt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "p = accuracy.eval(feed_dict = {X:test_Images[0:50], Y:test_Labels[0:50]})\n",
    "\n",
    "test = session.run(y_out,feed_dict = {X:test_Images[0:10], Y:test_Labels[0:10]})\n",
    "print(p)\n",
    "print(np.round(test))\n",
    "print(test_Labels[0:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
